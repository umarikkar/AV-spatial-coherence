{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\umari\\anaconda3\\envs\\DL38\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network path c:\\Users\\umari\\projects\\AV-spatial-coherence\\results\\checkpoints\\MC_full_AVOL_v3\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "import core.config as conf\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "from fn_networks import BackboneAud, SubnetAud, SubnetVid, show_feature_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.randn((2, 3, 224, 224))\n",
    "aud = torch.randn((2, 16, 960, 64))\n",
    "cam = torch.randn((2, 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = AVOL_r18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im backbone torch.Size([2, 256, 14, 14])\n",
      "im subnet torch.Size([2, 512, 7, 7])\n",
      "conv1 im torch.Size([2, 64, 7, 7])\n",
      "aud conv torch.Size([2, 64, 958, 62])\n",
      "aud back torch.Size([2, 128, 240, 16])\n",
      "aud sub torch.Size([2, 512])\n",
      "aud fc1 torch.Size([2, 64])\n",
      "aud fc2 torch.Size([2, 64, 1, 1])\n",
      "torch.Size([2, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "out = net(img, aud, cam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('DL38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1222a71dbe72e2a4a3c770f69a94992665f86f9a6ceb5bec610e6a8ad2150cd2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
