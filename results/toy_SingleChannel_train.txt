size=1024, BS=16, lambda=0.0001, heatmap=False, multi_mic=False ------------------------------->

2022-06-23 12:13:41.012238 n_batches 64, Epoch 1, Training loss 0.6959 Training acc 53.96%
2022-06-23 12:14:21.244728 n_batches 64, Epoch 2, Training loss 0.6417 Training acc 64.01%
2022-06-23 12:14:58.614875 n_batches 64, Epoch 3, Training loss 0.5513 Training acc 71.63%
2022-06-23 12:15:35.357249 n_batches 64, Epoch 4, Training loss 0.5189 Training acc 74.07%
2022-06-23 12:16:12.171413 n_batches 64, Epoch 5, Training loss 0.5237 Training acc 73.14%
2022-06-23 12:16:48.909103 n_batches 64, Epoch 6, Training loss 0.5067 Training acc 73.78%
2022-06-23 12:17:27.622892 n_batches 64, Epoch 7, Training loss 0.4867 Training acc 74.9%
2022-06-23 12:18:36.723187 n_batches 64, Epoch 8, Training loss 0.4646 Training acc 77.59%
2022-06-23 12:19:14.474156 n_batches 64, Epoch 9, Training loss 0.461 Training acc 77.2%
2022-06-23 12:19:55.655296 n_batches 64, Epoch 10, Training loss 0.471 Training acc 76.32%
2022-06-23 12:20:39.879259 n_batches 64, Epoch 11, Training loss 0.4266 Training acc 80.52%
2022-06-23 12:21:27.641142 n_batches 64, Epoch 12, Training loss 0.4312 Training acc 80.47%
2022-06-23 12:22:04.410158 n_batches 64, Epoch 13, Training loss 0.4327 Training acc 80.13%
2022-06-23 12:22:47.782736 n_batches 64, Epoch 14, Training loss 0.4184 Training acc 81.64%
2022-06-23 12:23:52.865835 n_batches 64, Epoch 15, Training loss 0.387 Training acc 83.5%
2022-06-23 12:25:07.991885 n_batches 64, Epoch 16, Training loss 0.4077 Training acc 81.64%
2022-06-23 12:26:01.482867 n_batches 64, Epoch 17, Training loss 0.3715 Training acc 83.94%
2022-06-23 12:26:49.388004 n_batches 64, Epoch 18, Training loss 0.3845 Training acc 83.79%
2022-06-23 12:27:32.051659 n_batches 64, Epoch 19, Training loss 0.3936 Training acc 83.3%
2022-06-23 12:28:26.442524 n_batches 64, Epoch 20, Training loss 0.3602 Training acc 85.01%
2022-06-23 12:29:10.101431 n_batches 64, Epoch 21, Training loss 0.3589 Training acc 84.47%
2022-06-23 12:29:58.472463 n_batches 64, Epoch 22, Training loss 0.3591 Training acc 85.16%
2022-06-23 12:30:36.447009 n_batches 64, Epoch 23, Training loss 0.3547 Training acc 85.69%
2022-06-23 12:31:13.474046 n_batches 64, Epoch 24, Training loss 0.3505 Training acc 85.74%
2022-06-23 12:31:50.542652 n_batches 64, Epoch 25, Training loss 0.3403 Training acc 86.62%
2022-06-23 12:32:27.393924 n_batches 64, Epoch 26, Training loss 0.3457 Training acc 86.04%
2022-06-23 12:33:04.242567 n_batches 64, Epoch 27, Training loss 0.3258 Training acc 87.35%
2022-06-23 12:33:41.069181 n_batches 64, Epoch 28, Training loss 0.3349 Training acc 87.35%
2022-06-23 12:34:17.890915 n_batches 64, Epoch 29, Training loss 0.332 Training acc 86.47%
2022-06-23 12:34:54.710481 n_batches 64, Epoch 30, Training loss 0.3308 Training acc 86.47%
2022-06-23 12:35:31.558519 n_batches 64, Epoch 31, Training loss 0.3174 Training acc 87.35%
2022-06-23 12:36:08.395327 n_batches 64, Epoch 32, Training loss 0.3005 Training acc 88.33%
2022-06-23 12:36:45.242916 n_batches 64, Epoch 33, Training loss 0.3103 Training acc 87.79%
2022-06-23 12:37:22.097002 n_batches 64, Epoch 34, Training loss 0.2992 Training acc 88.43%
2022-06-23 12:37:58.952029 n_batches 64, Epoch 35, Training loss 0.3047 Training acc 88.18%
2022-06-23 12:38:35.799173 n_batches 64, Epoch 36, Training loss 0.2763 Training acc 89.65%
2022-06-23 12:39:12.635915 n_batches 64, Epoch 37, Training loss 0.275 Training acc 89.4%
2022-06-23 12:39:49.460981 n_batches 64, Epoch 38, Training loss 0.2693 Training acc 89.65%
2022-06-23 12:40:26.283560 n_batches 64, Epoch 39, Training loss 0.2691 Training acc 90.43%
2022-06-23 12:41:03.121053 n_batches 64, Epoch 40, Training loss 0.2553 Training acc 90.62%