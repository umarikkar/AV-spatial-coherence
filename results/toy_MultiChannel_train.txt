size=1024, BS=16, lambda=0.0001, heatmap=False, multi_mic=False ------------------------------->

2022-06-23 15:29:23.976235 n_batches 64, Epoch 1, Training loss 0.6912, L2 loss 0.0094, Training acc 56.69%
2022-06-23 15:30:11.702677 n_batches 64, Epoch 2, Training loss 0.6532, L2 loss 0.0094, Training acc 62.16%
2022-06-23 15:30:59.449986 n_batches 64, Epoch 3, Training loss 0.6138, L2 loss 0.0094, Training acc 66.36%
2022-06-23 15:31:47.244892 n_batches 64, Epoch 4, Training loss 0.5991, L2 loss 0.0094, Training acc 67.58%
2022-06-23 15:32:35.038678 n_batches 64, Epoch 5, Training loss 0.5659, L2 loss 0.0094, Training acc 70.36%
2022-06-23 15:33:22.795569 n_batches 64, Epoch 6, Training loss 0.5302, L2 loss 0.0094, Training acc 73.05%
2022-06-23 15:34:10.597136 n_batches 64, Epoch 7, Training loss 0.4638, L2 loss 0.0094, Training acc 78.32%
2022-06-23 15:34:58.358483 n_batches 64, Epoch 8, Training loss 0.4283, L2 loss 0.0094, Training acc 80.57%
2022-06-23 15:35:46.159994 n_batches 64, Epoch 9, Training loss 0.4208, L2 loss 0.0095, Training acc 81.64%
2022-06-23 15:36:33.930611 n_batches 64, Epoch 10, Training loss 0.3926, L2 loss 0.0095, Training acc 83.54%
2022-06-23 15:37:21.729642 n_batches 64, Epoch 11, Training loss 0.3662, L2 loss 0.0095, Training acc 85.35%
2022-06-23 15:38:09.514220 n_batches 64, Epoch 12, Training loss 0.3757, L2 loss 0.0095, Training acc 85.16%
2022-06-23 15:38:57.266653 n_batches 64, Epoch 13, Training loss 0.359, L2 loss 0.0095, Training acc 85.4%
2022-06-23 15:39:45.889792 n_batches 64, Epoch 14, Training loss 0.3381, L2 loss 0.0095, Training acc 86.23%
2022-06-23 15:40:33.630331 n_batches 64, Epoch 15, Training loss 0.3628, L2 loss 0.0095, Training acc 84.33%
2022-06-23 15:41:22.063881 n_batches 64, Epoch 16, Training loss 0.3552, L2 loss 0.0095, Training acc 85.64%
2022-06-23 15:42:10.272948 n_batches 64, Epoch 17, Training loss 0.3432, L2 loss 0.0095, Training acc 85.89%
2022-06-23 15:42:57.845238 n_batches 64, Epoch 18, Training loss 0.3023, L2 loss 0.0095, Training acc 88.04%
2022-06-23 15:43:45.426114 n_batches 64, Epoch 19, Training loss 0.3241, L2 loss 0.0095, Training acc 87.65%
2022-06-23 15:44:33.058431 n_batches 64, Epoch 20, Training loss 0.3108, L2 loss 0.0095, Training acc 88.62%
2022-06-23 15:45:20.660902 n_batches 64, Epoch 21, Training loss 0.2849, L2 loss 0.0095, Training acc 89.11%
2022-06-23 15:46:08.261959 n_batches 64, Epoch 22, Training loss 0.2876, L2 loss 0.0095, Training acc 89.5%
2022-06-23 15:46:55.818763 n_batches 64, Epoch 23, Training loss 0.269, L2 loss 0.0095, Training acc 90.09%
2022-06-23 15:47:43.375107 n_batches 64, Epoch 24, Training loss 0.3029, L2 loss 0.0095, Training acc 89.11%
2022-06-23 15:48:32.437622 n_batches 64, Epoch 25, Training loss 0.2977, L2 loss 0.0095, Training acc 88.62%
2022-06-23 15:49:20.522523 n_batches 64, Epoch 26, Training loss 0.286, L2 loss 0.0095, Training acc 89.75%
2022-06-23 15:50:08.283826 n_batches 64, Epoch 27, Training loss 0.2754, L2 loss 0.0095, Training acc 90.04%
2022-06-23 15:50:56.173413 n_batches 64, Epoch 28, Training loss 0.2816, L2 loss 0.0095, Training acc 89.65%
2022-06-23 15:51:44.033925 n_batches 64, Epoch 29, Training loss 0.2537, L2 loss 0.0095, Training acc 91.46%
2022-06-23 15:52:31.938422 n_batches 64, Epoch 30, Training loss 0.2582, L2 loss 0.0095, Training acc 90.82%
2022-06-23 15:53:19.801571 n_batches 64, Epoch 31, Training loss 0.2294, L2 loss 0.0095, Training acc 92.63%
2022-06-23 15:54:07.580326 n_batches 64, Epoch 32, Training loss 0.2343, L2 loss 0.0095, Training acc 91.65%
2022-06-23 15:54:55.556554 n_batches 64, Epoch 33, Training loss 0.2569, L2 loss 0.0095, Training acc 90.53%
2022-06-23 15:55:43.534861 n_batches 64, Epoch 34, Training loss 0.232, L2 loss 0.0095, Training acc 92.04%
2022-06-23 15:56:32.972981 n_batches 64, Epoch 35, Training loss 0.2395, L2 loss 0.0095, Training acc 91.16%
2022-06-23 15:57:21.045668 n_batches 64, Epoch 36, Training loss 0.2461, L2 loss 0.0095, Training acc 91.16%
2022-06-23 15:58:08.985138 n_batches 64, Epoch 37, Training loss 0.2174, L2 loss 0.0095, Training acc 93.02%
2022-06-23 15:58:57.202987 n_batches 64, Epoch 38, Training loss 0.2091, L2 loss 0.0095, Training acc 92.82%
2022-06-23 15:59:45.683247 n_batches 64, Epoch 39, Training loss 0.2249, L2 loss 0.0095, Training acc 92.04%
2022-06-23 16:00:33.447419 n_batches 64, Epoch 40, Training loss 0.2168, L2 loss 0.0095, Training acc 92.48%